{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'SignLanguageDataset/train'\n",
    "valid_path = 'SignLanguageDataset/valid'\n",
    "test_path = 'SignLanguageDataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1512 images belonging to 10 classes.\n",
      "Found 500 images belonging to 10 classes.\n",
      "Found 50 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batchs = ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(train_path, target_size=(224,224), batch_size=10)\n",
    "valid_batchs = ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(valid_path, target_size=(224,224), batch_size=10)\n",
    "test_batchs = ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 1000)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 4,253,864\n",
      "Trainable params: 4,231,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet()\n",
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "x = mobile.layers[-6].output\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "model = Model(input=mobile.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "18/18 [==============================] - 12s 648ms/step - loss: 1.3042 - acc: 0.5778 - val_loss: 4.2619 - val_acc: 0.2600\n",
      "Epoch 2/60\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 0.7053 - acc: 0.7556 - val_loss: 3.8807 - val_acc: 0.2520\n",
      "Epoch 3/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.3881 - acc: 0.8889 - val_loss: 3.3208 - val_acc: 0.3600\n",
      "Epoch 4/60\n",
      "18/18 [==============================] - 5s 266ms/step - loss: 0.2183 - acc: 0.9220 - val_loss: 2.6139 - val_acc: 0.4320\n",
      "Epoch 5/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.1961 - acc: 0.9389 - val_loss: 2.8278 - val_acc: 0.4240\n",
      "Epoch 6/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.2281 - acc: 0.9278 - val_loss: 1.8690 - val_acc: 0.5080\n",
      "Epoch 7/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.3071 - acc: 0.9111 - val_loss: 1.2259 - val_acc: 0.6220\n",
      "Epoch 8/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.1697 - acc: 0.9500 - val_loss: 3.7445 - val_acc: 0.3060\n",
      "Epoch 9/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.1742 - acc: 0.9500 - val_loss: 4.2777 - val_acc: 0.2960\n",
      "Epoch 10/60\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 0.0722 - acc: 0.9778 - val_loss: 2.9948 - val_acc: 0.3280\n",
      "Epoch 11/60\n",
      "18/18 [==============================] - 4s 234ms/step - loss: 0.1032 - acc: 0.9511 - val_loss: 1.3578 - val_acc: 0.6740\n",
      "Epoch 12/60\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 0.0859 - acc: 0.9833 - val_loss: 0.5792 - val_acc: 0.7900\n",
      "Epoch 13/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.1409 - acc: 0.9556 - val_loss: 0.9879 - val_acc: 0.7660\n",
      "Epoch 14/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0863 - acc: 0.9722 - val_loss: 2.4899 - val_acc: 0.4620\n",
      "Epoch 15/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0604 - acc: 0.9722 - val_loss: 3.0039 - val_acc: 0.4520\n",
      "Epoch 16/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.1184 - acc: 0.9722 - val_loss: 2.6152 - val_acc: 0.3620\n",
      "Epoch 17/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.1331 - acc: 0.9667 - val_loss: 1.3804 - val_acc: 0.6060\n",
      "Epoch 18/60\n",
      "18/18 [==============================] - 4s 235ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.3513 - val_acc: 0.6080\n",
      "Epoch 19/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9414 - val_acc: 0.7120\n",
      "Epoch 20/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6398 - val_acc: 0.8100\n",
      "Epoch 21/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0395 - acc: 0.9778 - val_loss: 0.3997 - val_acc: 0.8660\n",
      "Epoch 22/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0448 - acc: 0.9833 - val_loss: 1.6808 - val_acc: 0.5680\n",
      "Epoch 23/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0539 - acc: 0.9889 - val_loss: 4.2966 - val_acc: 0.2780\n",
      "Epoch 24/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0814 - acc: 0.9667 - val_loss: 4.5336 - val_acc: 0.2840\n",
      "Epoch 25/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0415 - acc: 0.9833 - val_loss: 3.8075 - val_acc: 0.3580\n",
      "Epoch 26/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0573 - acc: 0.9778 - val_loss: 1.1234 - val_acc: 0.6720\n",
      "Epoch 27/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0250 - acc: 0.9889 - val_loss: 0.8782 - val_acc: 0.7200\n",
      "Epoch 28/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0258 - acc: 0.9944 - val_loss: 0.8919 - val_acc: 0.7280\n",
      "Epoch 29/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.5093 - val_acc: 0.8240\n",
      "Epoch 30/60\n",
      "18/18 [==============================] - 4s 235ms/step - loss: 0.3092 - acc: 0.8855 - val_loss: 7.8307 - val_acc: 0.1140\n",
      "Epoch 31/60\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.1214 - acc: 0.9722 - val_loss: 11.4753 - val_acc: 0.1020\n",
      "Epoch 32/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.1039 - acc: 0.9611 - val_loss: 4.2392 - val_acc: 0.3480\n",
      "Epoch 33/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.1545 - acc: 0.9667 - val_loss: 2.8352 - val_acc: 0.5240\n",
      "Epoch 34/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.1299 - acc: 0.9778 - val_loss: 2.1242 - val_acc: 0.6560\n",
      "Epoch 35/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0490 - acc: 0.9778 - val_loss: 1.6974 - val_acc: 0.6340\n",
      "Epoch 36/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0228 - acc: 0.9944 - val_loss: 0.5386 - val_acc: 0.8300\n",
      "Epoch 37/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0160 - acc: 0.9889 - val_loss: 0.3909 - val_acc: 0.8760\n",
      "Epoch 38/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.3762 - val_acc: 0.8780\n",
      "Epoch 39/60\n",
      "18/18 [==============================] - 4s 236ms/step - loss: 0.0159 - acc: 0.9944 - val_loss: 0.2595 - val_acc: 0.9200\n",
      "Epoch 40/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0295 - acc: 0.9889 - val_loss: 0.3279 - val_acc: 0.8940\n",
      "Epoch 41/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0154 - acc: 0.9944 - val_loss: 0.4406 - val_acc: 0.8560\n",
      "Epoch 42/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.3775 - val_acc: 0.8760\n",
      "Epoch 43/60\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.0359 - acc: 0.9944 - val_loss: 0.4356 - val_acc: 0.8640\n",
      "Epoch 44/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0242 - acc: 0.9889 - val_loss: 0.2957 - val_acc: 0.9000\n",
      "Epoch 45/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0065 - acc: 0.9944 - val_loss: 0.3161 - val_acc: 0.8940\n",
      "Epoch 46/60\n",
      "18/18 [==============================] - 4s 235ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3650 - val_acc: 0.8700\n",
      "Epoch 47/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0088 - acc: 0.9944 - val_loss: 0.2410 - val_acc: 0.9200\n",
      "Epoch 48/60\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.0132 - acc: 0.9944 - val_loss: 0.1902 - val_acc: 0.9360\n",
      "Epoch 49/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0600 - acc: 0.9833 - val_loss: 0.1911 - val_acc: 0.9340\n",
      "Epoch 50/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0501 - acc: 0.9833 - val_loss: 0.4882 - val_acc: 0.8160\n",
      "Epoch 51/60\n",
      "18/18 [==============================] - 4s 242ms/step - loss: 0.0200 - acc: 0.9944 - val_loss: 0.6853 - val_acc: 0.7840\n",
      "Epoch 52/60\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.0263 - acc: 0.9944 - val_loss: 0.8984 - val_acc: 0.6740\n",
      "Epoch 53/60\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.0414 - acc: 0.9833 - val_loss: 0.5991 - val_acc: 0.8140\n",
      "Epoch 54/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0195 - acc: 0.9889 - val_loss: 0.7756 - val_acc: 0.7840\n",
      "Epoch 55/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0332 - acc: 0.9889 - val_loss: 0.5699 - val_acc: 0.8160\n",
      "Epoch 56/60\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.0423 - acc: 0.9778 - val_loss: 0.6316 - val_acc: 0.7860\n",
      "Epoch 57/60\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5235 - val_acc: 0.8360\n",
      "Epoch 58/60\n",
      "18/18 [==============================] - 4s 239ms/step - loss: 0.0271 - acc: 0.9944 - val_loss: 0.7744 - val_acc: 0.7840\n",
      "Epoch 59/60\n",
      "18/18 [==============================] - 4s 238ms/step - loss: 0.0234 - acc: 0.9944 - val_loss: 0.4430 - val_acc: 0.8780\n",
      "Epoch 60/60\n",
      "18/18 [==============================] - 4s 240ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3891 - val_acc: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1f0a20e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batchs, steps_per_epoch=18, validation_data=valid_batchs, validation_steps=3, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_batchs.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batchs, steps=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batchs.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[3 0 0 0 0 1 0 0 1 0]\n",
      " [0 5 0 0 0 0 0 0 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 0 0]\n",
      " [0 0 2 0 0 0 3 0 0 0]\n",
      " [0 0 2 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 4 1]\n",
      " [0 0 0 0 0 0 0 0 0 5]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_class_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8','9']\n",
    "plot_confusion_matrix(cm, cm_class_labels, title='Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
